{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e3a99f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openml\n",
    "# from scipy.io import arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e54a7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1a4422a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorde\\AppData\\Local\\Temp\\ipykernel_36616\\1127533313.py:2: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, Y, categorical , f = data.get_data(target=data.default_target_attribute, dataset_format='array')\n"
     ]
    }
   ],
   "source": [
    "data = openml.datasets.get_dataset(1590, download_data=True) # Pegando os dados via API do OpenML\n",
    "X, Y, categorical , f = data.get_data(target=data.default_target_attribute, dataset_format='array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a1736265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48842, 14), (48842,))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "568e1519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:1001]\n",
    "Y = Y[:1001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "616e0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_is_categorical = list(zip(f, categorical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "98c3ba99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((927, 14), (927,))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_nan_indexes = np.where(np.isnan(X).any(axis=1))[0] ## Removendo os NANs\n",
    "\n",
    "X = np.delete(X, rows_nan_indexes, axis=0)\n",
    "Y = np.delete(Y, rows_nan_indexes, axis=0)\n",
    "X.shape, Y.shape   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d3e5be",
   "metadata": {},
   "source": [
    "# 1) Classificador KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "19518e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN: #Refazer diferente\n",
    "    def __init__(self, k, method): \n",
    "        #construtor em python que recebe o tipo de saída do modelo e os k vizinhos\n",
    "        self.k = k\n",
    "        self.method = method\n",
    "        \n",
    "    def fit(self, X_train, y_train): #Atribui os dados as variáveis\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train \n",
    "        \n",
    "        \n",
    "    def euclidean_distance(self, x1, x2): #Calcula distâncias euclidianas\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "    \n",
    "    def manhattan_distance(self, x1, x2): #Calcula distâncias de manhattan\n",
    "        return np.sum( abs(x1 - x2) )\n",
    "    \n",
    "    def predict(self, X):\n",
    "\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            # Calcula distâncias de x até todas as amostras de treino\n",
    "            if self.method == \"euclidean\":\n",
    "                distances = [self.euclidean_distance(x, x_train) for x_train in self.X_train]\n",
    "            elif self.method == \"manhattan\":\n",
    "                distances = [self.manhattan_distance(x, x_train) for x_train in self.X_train]\n",
    "\n",
    "            # Pega índices dos k vizinhos mais próximos\n",
    "            k_indices = np.argsort(distances)[:self.k]\n",
    "\n",
    "            # Extrai as classes correspondentes\n",
    "            k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
    "\n",
    "            # Conta a frequência de cada classe e pega a mais comum\n",
    "            unique, counts = np.unique(k_nearest_labels, return_counts=True)\n",
    "            predictions.append(unique[np.argmax(counts)])\n",
    "            \n",
    "            # print(predictions)\n",
    "\n",
    "        return np.array(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb827681",
   "metadata": {},
   "source": [
    "# 2) Classificador Bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "570ce458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesUnivariado:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X: np.ndarray, Y: np.ndarray):\n",
    "        self.classes = np.unique(Y)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Guardar valores em dicionários\n",
    "        self.means = {}\n",
    "        self.vars = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        # Calcular média, Desvio Padrão e prior para cada classe\n",
    "        for c in self.classes:\n",
    "            X_c = X[Y == c]\n",
    "            self.means[c] = X_c.mean(axis=0)\n",
    "            self.vars[c] = X_c.var(axis=0)\n",
    "            self.priors[c] = X_c.shape[0] / float(n_samples)\n",
    "    \n",
    "    def predict(self, X): # Para cada amostra em X, calcule a predição\n",
    "        return np.array([self._predict(x) for x in X])\n",
    "    \n",
    "    def _predict(self, x): # Calculando a posteriori para cada classe\n",
    "        posteriors = []\n",
    "\n",
    "        for c in self.classes:\n",
    "            \n",
    "            prior = np.log(self.priors[c]) # Soma em logs para evitar underflow\n",
    "            \n",
    "            classe_condicionada = np.sum( np.log( self._pdf(c, x )) )\n",
    "            \n",
    "            posterior = prior + classe_condicionada\n",
    "            \n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        # retorna a classe mais provável\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "    \n",
    "    def _pdf(self, c, x): # Calcula a função de densidade de probabilidade gaussiana\n",
    "        \n",
    "        mean = self.means[c] # Media da classe c\n",
    "        \n",
    "        var = self.vars[c] # Desvio Padrão da classe c\n",
    "        \n",
    "        # Evita var = 0\n",
    "        var = np.maximum(var, 1e-8)\n",
    "\n",
    "        numerator = np.exp(-((x - mean) ** 2) / (2 * var))\n",
    "        \n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        \n",
    "        return numerator / denominator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ab151",
   "metadata": {},
   "source": [
    "# Item B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449eff48",
   "metadata": {},
   "source": [
    "# 3) Classificador Bayesiano Multivariado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fbabf4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesMultivariado:\n",
    "    def _init_(self): \n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #Calcular médias, covariâncias e priori de cada classe\n",
    "    \n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.classes = np.unique(y)\n",
    "        \n",
    "    # Dicionários que vão armazenar os parâmetros de cada classe:\n",
    "        self.means = {}\n",
    "        self.covs = {}\n",
    "        self.priors = {}\n",
    "\n",
    "# percorre cada classe para calcular seus parâmetros\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.means[c] = X_c.mean(axis=0)\n",
    "            self.covs[c] = np.cov(X_c, rowvar=False)\n",
    "            self.priors[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def _pdf_multivariada(self, x, mean, cov):\n",
    "        \n",
    "        d = len(mean)\n",
    "        \n",
    "        cov_det = np.linalg.det(cov) # Determinante da matriz de covariância\n",
    "        \n",
    "        cov_inv = np.linalg.inv(cov) # Inversa da matriz de covariância\n",
    "        \n",
    "        denominador = 1.0 / np.sqrt((2 * np.pi) ** d * cov_det) \n",
    "        \n",
    "        x_menos_mean = np.transpose(x - mean) # Para fins de redução de cálculo na linha seguinte\n",
    "        \n",
    "        expoente = -0.5 * np.dot(np.dot(x_menos_mean, cov_inv), x_menos_mean.T)\n",
    "        \n",
    "        return float(denominador * np.exp(expoente.item()))\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        X = np.array(X)\n",
    "        \n",
    "        y_pred = []\n",
    "        \n",
    "        for x in X:\n",
    "            posteriors = []\n",
    "            \n",
    "            for c in self.classes:\n",
    "                \n",
    "                prior = np.log(self.priors[c]) # Todas amostras a prior das classes\n",
    "                \n",
    "                aproximacao = np.log(self._pdf_multivariada(x, self.means[c], self.covs[c]) + 1e-12) # Ao invés de multiplicar pequenas probabilidades, somamos os logaritmos para evitar underflow\n",
    "                \n",
    "                posterior = prior + aproximacao\n",
    "                \n",
    "                posteriors.append(posterior)\n",
    "                \n",
    "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
    "            \n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ab51e",
   "metadata": {},
   "source": [
    "## Perceptron Simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "76d07423",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronSimples:\n",
    "    def __init__(self,learning_rate=0.01, epochs=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape #dimensoes\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0 #inicializar os pesos e bias\n",
    "        for _ in range(self.epochs):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights)+self.bias\n",
    "                y_predicted = self._step_function(linear_output)\n",
    "                if y[idx] != y_predicted:\n",
    "                    update = self.learning_rate * (y[idx] - y_predicted)\n",
    "                    self.weights += update *x_i\n",
    "                    self.bias +=update\n",
    "                    \n",
    "    def _step_function(self,x):\n",
    "        return np.where(x>=0, 1, 0)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) +self.bias\n",
    "        y_predicted = self._step_function(linear_output)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199baff0",
   "metadata": {},
   "source": [
    "## MultiLayerPerceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ab2c7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, n_inputs, n_hidden, learning_rate=0.01, epochs=2000):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Inicialização dos pesos\n",
    "        \n",
    "        # Camada Oculta\n",
    "        self.W1 = np.random.randn(n_inputs, n_hidden) * 0.01\n",
    "        self.b1 = np.zeros((1, n_hidden)) # BIAS \n",
    "        \n",
    "        # Camada de Saída\n",
    "        self.W2 = np.random.randn(n_hidden, 1) * 0.01\n",
    "        self.b2 = np.zeros((1, 1)) # BIAS\n",
    "\n",
    "    def sigmoid(self, x): # Função de ativação sigmoide\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_deriv(self, s): # Derivada da função sigmoide\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        m = X.shape[0]  # número de amostras\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            # CAMADA OCULTA\n",
    "            \n",
    "            # FORWARD\n",
    "            \n",
    "            Z1 = np.dot(X, self.W1) + self.b1\n",
    "            A1 = self.sigmoid(Z1)\n",
    "            \n",
    "            # CAMADA DE SAÍDA\n",
    "            \n",
    "            Z2 = np.dot(A1, self.W2) + self.b2\n",
    "            A2 = self.sigmoid(Z2)\n",
    "\n",
    "            # BACKPROPAGATION\n",
    "            dZ2 = A2 - y.reshape(-1, 1)\n",
    "            dW2 = np.dot(A1.T, dZ2) / m\n",
    "            db2 = np.mean(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "            dA1 = np.dot(dZ2, self.W2.T)\n",
    "            dZ1 = dA1 * self.sigmoid_deriv(A1) \n",
    "            dW1 = np.dot(X.T, dZ1) / m\n",
    "            db1 = np.mean(dZ1, axis=0, keepdims=True)\n",
    "\n",
    "            # AJUSTES DE PESO\n",
    "            self.W1 -= self.lr * dW1\n",
    "            self.b1 -= self.lr * db1\n",
    "            self.W2 -= self.lr * dW2\n",
    "            self.b2 -= self.lr * db2\n",
    "\n",
    "    def predict(self, X):\n",
    "        Z1 = np.dot(X, self.W1) + self.b1\n",
    "        A1 = self.sigmoid(Z1)\n",
    "        \n",
    "        Z2 = np.dot(A1, self.W2) + self.b2\n",
    "        A2 = self.sigmoid(Z2)\n",
    "        \n",
    "        return (A2 >= 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a7d76",
   "metadata": {},
   "source": [
    "# 4) Validaçao Cruzada “10-folds” (com random state=42) para avaliar e comparar os classificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e4f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class K_FOLD:\n",
    "    def __init__(self, k, models: dict, seed=42):\n",
    "        self.k = k\n",
    "        self.models = models\n",
    "        self.seed = seed\n",
    "        np.random.seed(seed) # Seed para reprodutibilidade\n",
    "\n",
    "    def split(self, X, Y):\n",
    "        n_samples = X.shape[0]\n",
    "        fold_size = n_samples // self.k\n",
    "        indices = np.arange(n_samples)\n",
    "        np.random.shuffle(indices) # Embaralha os índices dos dados aleatoriamente\n",
    "\n",
    "        for i in range(self.k):\n",
    "            \n",
    "            start = i * fold_size\n",
    "            \n",
    "            end = start + fold_size if i != self.k - 1 else n_samples # Garante que o último fold pegue todos os dados restantes\n",
    "            \n",
    "            test_idx = indices[start:end]\n",
    "            \n",
    "            train_idx = np.concatenate((indices[:start], indices[end:]))\n",
    "            \n",
    "            yield X[train_idx], X[test_idx], Y[train_idx], Y[test_idx] # Mantem a função meio que pausada esperando algum retorno\n",
    "\n",
    "    def accuracy(self, Y_true, Y_pred):\n",
    "        return np.sum(Y_true == Y_pred) / len(Y_true)\n",
    "\n",
    "    def precision(self, Y_true, Y_pred):\n",
    "        precisions = []\n",
    "        classes = np.unique(Y_true)\n",
    "\n",
    "        for c in classes:\n",
    "            tp = np.sum((Y_true == c) & (Y_pred == c))\n",
    "            pred_pos = np.sum(Y_pred == c)\n",
    "            prec = tp / pred_pos if pred_pos > 0 else 0\n",
    "            precisions.append(prec)\n",
    "\n",
    "        return precisions\n",
    "\n",
    "    def recall(self, Y_true, Y_pred):\n",
    "        recalls = []\n",
    "        classes = np.unique(Y_true)\n",
    "        for c in classes:\n",
    "            tp = np.sum((Y_true == c) & (Y_pred == c))\n",
    "            total_real = np.sum(Y_true == c)\n",
    "            recalls.append(tp / total_real if total_real > 0 else 0)\n",
    "        return recalls\n",
    "\n",
    "    def f1_score(self, Y_true, Y_pred):\n",
    "        precisao = np.mean(self.precision(Y_true, Y_pred))\n",
    "\n",
    "        recall = np.mean(self.recall(Y_true, Y_pred))\n",
    "        \n",
    "        if (precisao + recall) == 0:\n",
    "            return 0\n",
    "        return 2 * (precisao * recall) / (precisao + recall)\n",
    "\n",
    "    def evaluate(self, model_name: str, X, Y):\n",
    "        model_data = self.models[model_name]\n",
    "\n",
    "        acc_scores = []\n",
    "        prec_scores = []\n",
    "        f1_scores = []\n",
    "        train_times = []\n",
    "        test_times = []\n",
    "        \n",
    "        for X_train, X_test, Y_train, Y_test in self.split(X, Y):\n",
    "            \n",
    "            # Cria um modelo novo (zerado) usando a factory\n",
    "            model = model_data[\"factory\"]()\n",
    "\n",
    "            # Treino\n",
    "            t0 = time.time()\n",
    "            model.fit(X_train, Y_train)\n",
    "            train_time = time.time() - t0\n",
    "\n",
    "            # Teste\n",
    "            t1 = time.time()\n",
    "            preds = model.predict(X_test)\n",
    "            test_time = time.time() - t1\n",
    "            \n",
    "            # Métricas\n",
    "            acc = self.accuracy(Y_test, preds)\n",
    "            # print(acc)\n",
    "            prec = self.precision(Y_test, preds)\n",
    "            # print(preds)\n",
    "            f1 = self.f1_score(Y_test, preds)\n",
    "            # print(f1)\n",
    "\n",
    "\n",
    "            acc_scores.append(acc)\n",
    "            prec_scores.append(prec)\n",
    "            f1_scores.append(f1)\n",
    "            train_times.append(train_time)\n",
    "            test_times.append(test_time)\n",
    "            \n",
    "\n",
    "    \n",
    "        #  Resultados finais - Medias\n",
    "        model_data[\"acuracia_media\"] = np.mean(acc_scores)\n",
    "        model_data[\"precisao_media\"] = np.mean(prec_scores)\n",
    "        model_data[\"f1_score_medio\"] = np.mean(f1_scores)\n",
    "\n",
    "        #  Resultados finais - DP\n",
    "        model_data[\"dp_acuracia\"] = np.std(acc_scores)\n",
    "        model_data[\"dp_precisao\"] = np.std(prec_scores)\n",
    "        model_data[\"dp_f1\"] = np.std(f1_scores)\n",
    "        \n",
    "        #  Resultados finais - Tempos\n",
    "        model_data[\"tempo_treino\"] = np.mean(train_times)\n",
    "        model_data[\"tempo_teste\"] = np.mean(test_times)\n",
    "\n",
    "        print(f\"\\nModelo: {model_name}\")\n",
    "        print(f\"Acurácia média: {model_data['acuracia_media']:.4f}\")\n",
    "        print(f\"Variância acurácia: {model_data['dp_acuracia']:.4f}\")\n",
    "        print(f\"Precisão média: {model_data['precisao_media']:.4f}\")\n",
    "        print(f\"Variância precisão: {model_data['dp_precisao']:.4f}\")\n",
    "        print(f\"F1-score médio: {model_data['f1_score_medio']:.4f}\")\n",
    "        print(f\"Variância F1-score: {model_data['dp_f1']:.4f}\")\n",
    "        print(f\"Tempo médio treino: {model_data['tempo_treino']:.4f}s\")\n",
    "        print(f\"Tempo médio teste: {model_data['tempo_teste']:.4f}s\")\n",
    "\n",
    "        return model_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "db3b0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNI_K = 5\n",
    "UNI_EPOCHS = 1000\n",
    "UNI_LEARNING_RATE = 0.001\n",
    "\n",
    "models = {\n",
    "    \"KnnEuclidean\": {\n",
    "        \"factory\": lambda: KNN(k=UNI_K, method=\"euclidean\"), \n",
    "        \"acuracia_media\" : None,\n",
    "        \"dp_acuracia\" : None,\n",
    "        \"precisao_media\" : None,\n",
    "        \"dp_precisao\" : None, \n",
    "        \"f1_score_medio\" : None,\n",
    "        \"dp_f1\" : None, \n",
    "        \"tempo_teste\" : None, \n",
    "        \"tempo_treino\" : None\n",
    "        },\n",
    "    \"KnnManhattan\": {\n",
    "        \"factory\": lambda: KNN(k=UNI_K, method=\"manhattan\"), \n",
    "        \"acuracia_media\" : None,\n",
    "        \"dp_acuracia\" : None,\n",
    "        \"precisao_media\" : None,\n",
    "        \"dp_precisao\" : None, \n",
    "        \"f1_score_medio\" : None,\n",
    "        \"dp_f1\" : None, \n",
    "        \"tempo_teste\" : None, \n",
    "        \"tempo_treino\" : None\n",
    "        },\n",
    "    \"NaiveBayesUnivariado\": {\n",
    "        \"factory\": lambda: NaiveBayesUnivariado(), \n",
    "        \"acuracia_media\" : None,\n",
    "        \"dp_acuracia\" : None,\n",
    "        \"precisao_media\" : None,\n",
    "        \"dp_precisao\" : None, \n",
    "        \"f1_score_medio\" : None,\n",
    "        \"dp_f1\" : None, \n",
    "        \"tempo_teste\" : None, \n",
    "        \"tempo_treino\" : None\n",
    "        },\n",
    "    \"NaiveBayesMultivariado\": {\n",
    "        \"factory\": lambda: NaiveBayesMultivariado(), \n",
    "        \"acuracia_media\" : None,\n",
    "        \"dp_acuracia\" : None,\n",
    "        \"precisao_media\" : None,\n",
    "        \"dp_precisao\" : None, \n",
    "        \"f1_score_medio\" : None,\n",
    "        \"dp_f1\" : None, \n",
    "        \"tempo_teste\" : None, \n",
    "        \"tempo_treino\" : None\n",
    "        },\n",
    "    \"PerceptronSimples\": {\n",
    "        \"factory\": lambda: PerceptronSimples(learning_rate=UNI_LEARNING_RATE, epochs=UNI_EPOCHS), \n",
    "        \"acuracia_media\" : None,\n",
    "        \"dp_acuracia\" : None,\n",
    "        \"precisao_media\" : None,\n",
    "        \"dp_precisao\" : None, \n",
    "        \"f1_score_medio\" : None,\n",
    "        \"dp_f1\" : None, \n",
    "        \"tempo_teste\" : None, \n",
    "        \"tempo_treino\" : None\n",
    "    },\n",
    "    \"MultiLayerPerceptron\": {\n",
    "        \"factory\": lambda: MLP(n_inputs=X.shape[1], n_hidden=4, learning_rate=UNI_LEARNING_RATE, epochs=UNI_EPOCHS), \n",
    "        \"acuracia_media\" : None,\n",
    "        \"dp_acuracia\" : None,\n",
    "        \"precisao_media\" : None,\n",
    "        \"dp_precisao\" : None, \n",
    "        \"f1_score_medio\" : None,\n",
    "        \"dp_f1\" : None, \n",
    "        \"tempo_teste\" : None, \n",
    "        \"tempo_treino\" : None\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "499de505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[np.float64(0.4), np.float64(0.7241379310344828)], [np.float64(0.5), np.float64(0.7380952380952381)], [np.float64(0.5714285714285714), np.float64(0.788235294117647)], [np.float64(0.5555555555555556), np.float64(0.7469879518072289)], [np.float64(0.0), np.float64(0.75)], [np.float64(0.45454545454545453), np.float64(0.7777777777777778)], [np.float64(0.6), np.float64(0.7931034482758621)], [np.float64(0.4444444444444444), np.float64(0.7831325301204819)], [np.float64(0.25), np.float64(0.7386363636363636)], [np.float64(0.35714285714285715), np.float64(0.8470588235294118)]]\n",
      "\n",
      "Modelo: KnnEuclidean\n",
      "Acurácia média: 0.7408\n",
      "Variância acurácia: 0.0267\n",
      "Precisão média: 0.5910\n",
      "Variância precisão: 0.2162\n",
      "F1-score médio: 0.5642\n",
      "Variância F1-score: 0.0605\n",
      "Tempo médio treino: 0.0000s\n",
      "Tempo médio teste: 0.2446s\n",
      "[[np.float64(0.3333333333333333), np.float64(0.686046511627907)], [np.float64(0.2), np.float64(0.7701149425287356)], [np.float64(0.46153846153846156), np.float64(0.759493670886076)], [np.float64(0.5), np.float64(0.8255813953488372)], [np.float64(0.5555555555555556), np.float64(0.7108433734939759)], [np.float64(0.5), np.float64(0.7954545454545454)], [np.float64(0.14285714285714285), np.float64(0.7764705882352941)], [np.float64(0.4166666666666667), np.float64(0.8125)], [np.float64(0.25), np.float64(0.7976190476190477)], [np.float64(0.3076923076923077), np.float64(0.7093023255813954)]]\n",
      "\n",
      "Modelo: KnnManhattan\n",
      "Acurácia média: 0.7298\n",
      "Variância acurácia: 0.0458\n",
      "Precisão média: 0.5656\n",
      "Variância precisão: 0.2224\n",
      "F1-score médio: 0.5462\n",
      "Variância F1-score: 0.0495\n",
      "Tempo médio treino: 0.0000s\n",
      "Tempo médio teste: 0.2028s\n",
      "[[np.float64(0.6), np.float64(0.8441558441558441)], [np.float64(0.5), np.float64(0.8658536585365854)], [np.float64(0.6428571428571429), np.float64(0.8076923076923077)], [np.float64(0.8421052631578947), np.float64(0.8493150684931506)], [np.float64(0.5), np.float64(0.8375)], [np.float64(0.35714285714285715), np.float64(0.7564102564102564)], [np.float64(0.75), np.float64(0.85)], [np.float64(0.75), np.float64(0.7875)], [np.float64(0.6363636363636364), np.float64(0.7901234567901234)], [np.float64(0.7272727272727273), np.float64(0.7727272727272727)]]\n",
      "\n",
      "Modelo: NaiveBayesUnivariado\n",
      "Acurácia média: 0.7909\n",
      "Variância acurácia: 0.0411\n",
      "Precisão média: 0.7234\n",
      "Variância precisão: 0.1374\n",
      "F1-score médio: 0.6819\n",
      "Variância F1-score: 0.0643\n",
      "Tempo médio treino: 0.0005s\n",
      "Tempo médio teste: 0.0016s\n",
      "[[0, np.float64(0.8260869565217391)], [0, np.float64(0.7608695652173914)], [0, np.float64(0.6956521739130435)], [0, np.float64(0.7282608695652174)], [0, np.float64(0.7608695652173914)], [0, np.float64(0.717391304347826)], [0, np.float64(0.7391304347826086)], [0, np.float64(0.7608695652173914)], [0, np.float64(0.8043478260869565)], [0, np.float64(0.7272727272727273)]]\n",
      "\n",
      "Modelo: NaiveBayesMultivariado\n",
      "Acurácia média: 0.7521\n",
      "Variância acurácia: 0.0377\n",
      "Precisão média: 0.3760\n",
      "Variância precisão: 0.3770\n",
      "F1-score médio: 0.4290\n",
      "Variância F1-score: 0.0121\n",
      "Tempo médio treino: 0.0006s\n",
      "Tempo médio teste: 0.0033s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorde\\AppData\\Local\\Temp\\ipykernel_36616\\3256339169.py:31: RuntimeWarning: divide by zero encountered in log\n",
      "  classe_condicionada = np.sum( np.log( self._pdf(c, x )) )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[np.float64(0.6470588235294118), np.float64(0.76)], [np.float64(0.8), np.float64(0.7816091954022989)], [np.float64(0.42857142857142855), np.float64(0.8)], [np.float64(0.6153846153846154), np.float64(0.7341772151898734)], [np.float64(0.6), np.float64(0.8658536585365854)], [np.float64(0.4117647058823529), np.float64(0.8266666666666667)], [np.float64(0.7142857142857143), np.float64(0.7764705882352941)], [np.float64(0.2717391304347826), 0], [np.float64(0.5333333333333333), np.float64(0.8051948051948052)], [np.float64(0.20202020202020202), 0]]\n",
      "\n",
      "Modelo: PerceptronSimples\n",
      "Acurácia média: 0.6604\n",
      "Variância acurácia: 0.2144\n",
      "Precisão média: 0.5787\n",
      "Variância precisão: 0.2659\n",
      "F1-score médio: 0.5540\n",
      "Variância F1-score: 0.1843\n",
      "Tempo médio treino: 2.8693s\n",
      "Tempo médio teste: 0.0000s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lorde\\AppData\\Local\\Temp\\ipykernel_36616\\2982984344.py:17: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, np.float64(0.7608695652173914)], [0, np.float64(0.6956521739130435)], [0, np.float64(0.782608695652174)], [0, np.float64(0.6847826086956522)], [0, np.float64(0.75)], [0, np.float64(0.7282608695652174)], [0, np.float64(0.8043478260869565)], [0, np.float64(0.7282608695652174)], [0, np.float64(0.7282608695652174)], [0, np.float64(0.8484848484848485)]]\n",
      "\n",
      "Modelo: MultiLayerPerceptron\n",
      "Acurácia média: 0.7512\n",
      "Variância acurácia: 0.0474\n",
      "Precisão média: 0.3756\n",
      "Variância precisão: 0.3771\n",
      "F1-score médio: 0.4285\n",
      "Variância F1-score: 0.0152\n",
      "Tempo médio treino: 0.1121s\n",
      "Tempo médio teste: 0.0001s\n"
     ]
    }
   ],
   "source": [
    "#Executando K-Fold Cross Validation\n",
    "k_FOLD = K_FOLD(k=10, models=models)\n",
    "\n",
    "for model_name in models.keys():\n",
    "    k_FOLD.evaluate(model_name,X ,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto_final_av3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
